{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "file_path = \"C:/Users/HP/Desktop/Dataset/archive/amazon_beauty_subset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the desired columns\n",
    "desired_columns = ['UserId', 'ProductId', 'Rating', 'Timestamp']\n",
    "selected_df = df[desired_columns]\n",
    "\n",
    "# Save the selected columns to a new CSV file\n",
    "output_file_path = \"C:/Users/HP/Desktop/Dataset/archive/Svd_Dataset.csv\"\n",
    "selected_df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV train and test files have been saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths to the CSV files\n",
    "amazon_beauty_subset_path = \"C:/Users/HP/Desktop/Dataset/archive/amazon_beauty_subset.csv\"\n",
    "svd_dataset_subset_path = \"C:/Users/HP/Desktop/Dataset/archive/Svd_Dataset.csv\"\n",
    "filtered_csv_train_path = \"C:/Users/HP/Desktop/Dataset/archive/amazon_beauty_filtered_train.csv\"\n",
    "filtered_csv_test_path = \"C:/Users/HP/Desktop/Dataset/archive/amazon_beauty_filtered_test.csv\"\n",
    "\n",
    "# Load the amazon_beauty_subset.csv file\n",
    "amazon_beauty_subset_df = pd.read_csv(amazon_beauty_subset_path)\n",
    "\n",
    "# Load the dataset using Surprise's Dataset class\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(1, 5), skip_lines=1)\n",
    "data = Dataset.load_from_file(svd_dataset_subset_path, reader=reader)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.3)\n",
    "\n",
    "# Convert trainset to pandas DataFrame\n",
    "trainset_df = pd.DataFrame([{\n",
    "    'UserId': trainset.to_raw_uid(uid),\n",
    "    'ProductId': trainset.to_raw_iid(iid),\n",
    "    'Rating': rating\n",
    "} for uid, user_ratings in trainset.ur.items() for iid, rating in user_ratings])\n",
    "\n",
    "# Convert testset to pandas DataFrame\n",
    "testset_df = pd.DataFrame([{\n",
    "    'UserId': uid,\n",
    "    'ProductId': iid,\n",
    "    'Rating': rating\n",
    "} for uid, iid, rating in testset])\n",
    "\n",
    "# Filter the amazon_beauty_subset_df to keep only the entries in the trainset\n",
    "content_trainset = amazon_beauty_subset_df[\n",
    "    amazon_beauty_subset_df[['UserId', 'ProductId']].apply(tuple, axis=1).isin(\n",
    "        trainset_df[['UserId', 'ProductId']].apply(tuple, axis=1)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Filter the amazon_beauty_subset_df to keep only the entries in the testset\n",
    "content_testset = amazon_beauty_subset_df[\n",
    "    amazon_beauty_subset_df[['UserId', 'ProductId']].apply(tuple, axis=1).isin(\n",
    "        testset_df[['UserId', 'ProductId']].apply(tuple, axis=1)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Save the filtered DataFrames to new CSV files\n",
    "content_trainset.to_csv(filtered_csv_train_path, index=False)\n",
    "content_testset.to_csv(filtered_csv_test_path, index=False)\n",
    "\n",
    "print(\"Filtered CSV train and test files have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x19c644a6690>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD()\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been loaded and split successfully.\n"
     ]
    }
   ],
   "source": [
    "# Paths to the CSV files\n",
    "Trainset_path = \"C:/Users/HP/Desktop/Dataset/archive/amazon_beauty_filtered_train.csv\"\n",
    "Testset_path = \"C:/Users/HP/Desktop/Dataset/archive/amazon_beauty_filtered_test.csv\"\n",
    "\n",
    "# Load your pre-split datasets\n",
    "trainset_df = pd.read_csv(Trainset_path)\n",
    "testset_df = pd.read_csv(Testset_path)\n",
    "\n",
    "item_ids = trainset_df['ProductId'].unique()\n",
    "\n",
    "# Split the data into features and target for the training set\n",
    "X_train = trainset_df['ProductType']\n",
    "y_train = trainset_df['Rating']\n",
    "\n",
    "# Split the data into features and target for the testing set\n",
    "X_test = testset_df['ProductType']\n",
    "y_test = testset_df['Rating']\n",
    "\n",
    "print(\"Data has been loaded and split successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load your pre-split datasets\n",
    "trainset_df = pd.read_csv(Trainset_path)\n",
    "testset_df = pd.read_csv(Testset_path)\n",
    "\n",
    "# Concatenate training and test data\n",
    "all_data = pd.concat([trainset_df[['UserId', 'ProductId']], testset_df[['UserId', 'ProductId']]])\n",
    "\n",
    "# Fit OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(all_data)\n",
    "\n",
    "# Transform training data\n",
    "X_train_user_product = encoder.transform(trainset_df[['UserId', 'ProductId']])\n",
    "\n",
    "# Convert the text data into TF-IDF vectors\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_product_type_tfidf = tfidf_vectorizer.fit_transform(trainset_df['ProductType'])\n",
    "\n",
    "# Combine the encoded user-product features with the product type TF-IDF vectors\n",
    "X_train = hstack([X_train_user_product, X_train_product_type_tfidf])\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, trainset_df['Rating'])\n",
    "\n",
    "# Create lists to store the data\n",
    "user_ids = []\n",
    "product_ids = []\n",
    "predicted_ratings = []\n",
    "\n",
    "# Iterate over each unique user and product pair in the test set\n",
    "for index, row in testset_df.iterrows():\n",
    "    user_id = row['UserId']\n",
    "    product_id = row['ProductId']\n",
    "    user_product_features = encoder.transform([[user_id, product_id]])\n",
    "    product_type = row['ProductType']\n",
    "    product_type_tfidf = tfidf_vectorizer.transform([product_type])\n",
    "    \n",
    "    # Combine the features\n",
    "    features = hstack([user_product_features, product_type_tfidf])\n",
    "    \n",
    "    # Predict the rating\n",
    "    predicted_rating = model.predict(features)[0]\n",
    "    \n",
    "    # Append the data to the lists\n",
    "    user_ids.append(user_id)\n",
    "    product_ids.append(product_id)\n",
    "    predicted_ratings.append(predicted_rating)\n",
    "\n",
    "# Create a dataframe to store the predicted ratings\n",
    "predicted_ratings_df = pd.DataFrame({'UserId': user_ids, 'ProductId': product_ids, 'PredictedRating': predicted_ratings})\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "predicted_ratings_df.to_csv(\"predicted_ratings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hybrid_recommendations(user_id, svd_model, item_ids, item_similarities, top_n, alpha):\n",
    "    # Initialize a list to store hybrid scores for each item\n",
    "    hybrid_scores = []\n",
    "\n",
    "    # Iterate over each item\n",
    "    for item_id in item_ids:\n",
    "        # Predict the rating for the current user and item using SVD\n",
    "        predicted_rating = svd_model.predict(user_id, item_id).est\n",
    "        content_rating_series = item_similarities.loc[(item_similarities['UserId'] == user_id) & (item_similarities['ProductId'] == item_id), 'PredictedRating']\n",
    "        # If content_rating_series is empty, set the content_rating to 0\n",
    "        content_rating = content_rating_series.iloc[0] if not content_rating_series.empty else 0\n",
    "\n",
    "        # Compute the hybrid score by combining collaborative filtering and content-based filtering\n",
    "        hybrid_score = alpha * predicted_rating + (1 - alpha) * content_rating\n",
    "\n",
    "        # Append the hybrid score to the list\n",
    "        hybrid_scores.append((item_id, hybrid_score))\n",
    "\n",
    "    # Sort the hybrid scores in descending order\n",
    "    hybrid_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract the top N recommended items\n",
    "    top_recommendations = [item_id for item_id, _ in hybrid_scores[:top_n]]\n",
    "\n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended items for user A3BCI5FNQCEJM6 : ['B0030O3VRW', 'B008TBTA6C', 'B00GS83884', 'B0083QNBCM', 'B005OSQGN8', 'B002TPQPEE', 'B000F35R00', 'B00067YSLO', 'B000Q7XDR4', 'B009GYVMAS']\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.read_csv(\"predicted_ratings.csv\")\n",
    "# Example usage: recommend top 5 items for user 1 with alpha=0.5\n",
    "user_id = 'A3BCI5FNQCEJM6'\n",
    "recommended_items = hybrid_recommendations(user_id, svd_model=svd, item_ids=item_ids, item_similarities=predictions, top_n=10, alpha=0.5)\n",
    "print(\"Top 5 recommended items for user\", user_id, \":\", recommended_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommendations_Test(user_id, svd_model, item_ids, item_similarities, alpha):\n",
    "    hybrid_scores = {}\n",
    "\n",
    "    for item_id in item_ids:\n",
    "        predicted_rating = svd_model.predict(user_id, item_id).est\n",
    "        content_rating_series = item_similarities.loc[(item_similarities['UserId'] == user_id) & (item_similarities['ProductId'] == item_id), 'PredictedRating']\n",
    "        content_rating = content_rating_series.iloc[0] if not content_rating_series.empty else 0\n",
    "\n",
    "        # Compute the hybrid score by combining collaborative filtering and content-based filtering\n",
    "        hybrid_score = alpha * predicted_rating + (1 - alpha) * content_rating\n",
    "\n",
    "        # Append the hybrid score to the list\n",
    "        hybrid_scores[item_id] = hybrid_score\n",
    "\n",
    "    return hybrid_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluate_model function\n",
    "def evaluate_model(svd_model, testset, item_similarities, alpha, threshold=3.5):\n",
    "    actual_ratings = []\n",
    "    predicted_ratings = []\n",
    "    actual_hits = []\n",
    "    predicted_hits = []\n",
    "\n",
    "    for user_id, item_id, actual_rating in testset:\n",
    "        item_ids = [item_id]\n",
    "        hybrid_scores = hybrid_recommendations_Test(user_id, svd_model, item_ids, item_similarities, alpha)\n",
    "        predicted_rating = hybrid_scores.get(item_id, 0)\n",
    "        actual_ratings.append(actual_rating)\n",
    "        predicted_ratings.append(predicted_rating)\n",
    "\n",
    "        # Convert ratings to binary hits\n",
    "        actual_hits.append(1 if actual_rating >= threshold else 0)\n",
    "        predicted_hits.append(1 if predicted_rating >= threshold else 0)\n",
    "\n",
    "    mse = mean_squared_error(actual_ratings, predicted_ratings)\n",
    "    rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "    mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(actual_hits, predicted_hits, average='binary')\n",
    "    hit_rate = np.mean(np.array(actual_hits) == np.array(predicted_hits))\n",
    "\n",
    "    return rmse, mse, mae, precision, recall, f1, hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.8037882601251443, RMSE: 1.3430518456579197, MAE: 1.0477103468004454\n",
      "Precision: 0.7853977632411901, Recall: 0.8105400696864111, F1 Score: 0.7977708712892508, Hit Rate: 0.6855\n"
     ]
    }
   ],
   "source": [
    "testset3 = trainset.build_testset()\n",
    "\n",
    "alpha = 0\n",
    "\n",
    "# Evaluate the model\n",
    "rmse, mse, mae, precision, recall, f1, hit_rate = evaluate_model(svd, testset, predictions, alpha, threshold=4)\n",
    "print(f'MSE: {mse}, RMSE: {rmse}, MAE: {mae}')\n",
    "print(f'Precision: {precision}, Recall: {recall}, F1 Score: {f1}, Hit Rate: {hit_rate}')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
